[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.18467564.svg)](https://doi.org/10.5281/zenodo.18467564)

<h1>
  <img src="app/public/baseAL_logo.png" alt="Logo" width="35" height="30">
  BaseAL - Active Learning Baseline
</h1>


>BaseAL is an framework for developing and evaluating active learning methods. BaseAL (v1.0.0) currently focuses on audio and bioacoustic data. 

The tool provides a complete pipeline for evaluating sampling strategies and 3D visualisation.

![Demo](demo.gif)
*Demo of 3D visualisation.*

### Key Features

- **Experiment Management**: Track and compare different active learning configurations
- **Interactive 3D Visualisation**: Explore high-dimensional embeddings using PCA/UMAP reduction with an interactive Three.js interface
- **Multiple Sampling Strategies**: Compare different sampling and diversification strategies
- **Model Integration**: Built on [Bacpipe](https://github.com/bioacoustic-ai/bacpipe) for seamless integration with bioacoustic models

**For BaseAL compatible dataset generation see the [dataset generator](https://github.com/BenMcEwen1/dataset-generator). You can download the ESC50 demo data [here](https://drive.google.com/file/d/183yLkZ1G8W3nXESkxcs1NERPGuFhofXu/view?usp=sharing).*

## Setup

### 1. Clone the Repository

```bash
git clone https://github.com/benmcewen1/BaseAL.git
cd BaseAL
```

### 2. Set Up Python Dependencies (Backend)

```bash
uv sync
```

**Dependencies**: see [pyproject.toml](pyproject.toml)

### 3. Set Up the Frontend (Web Interface)

```bash
cd app
npm install
```

## Quick Start

### 1. Start the API Server

```bash
cd api
python main.py
```

The API will be available at `http://localhost:8000`

You can verify it's running by visiting `http://localhost:8000/docs` for the interactive API documentation.

### 2. Start the Web Interface

Open a new terminal window and run:

```bash
cd app
npm run dev
```

The web interface will be available at `http://localhost:5173`

### 3. Explore Embeddings

1. Open `http://localhost:5173` in your browser
2. Check **"Use Real Embeddings (API)"** to connect to the backend
3. Select a **model** and **dataset** from the dropdown menus
4. Click **"Load Embeddings"** to generate and visualize embeddings
5. Use **Run/Run All** buttons to step through AL cycles
6. Interact with the 3D scatter plot to explore your data

## To run BaseAL using an Apptainer container on an HPC system, follow these steps:
### 1. Build the Apptainer Image

```bash
cd /path/to/BaseAL
apptainer build --fakeroot apptainer_build/baseal.def baseal.sif
```

### 2. Start shell within the Apptainer container

```bash
apptainer shell --bind /any/required/paths:/mnt baseal.sif
```

### 3. run the same commands as in the Quick Start section above.

## Citation

If you use this software, please cite:
```bibtex
@software{mcewen_baseal,
  author={McEwen, Ben and Zhang, Shiqi},
  title={{BaseAL}: Active Learning Baseline},
  year=2026,
  version={v1.1.0},
  publisher={Zenodo},
  doi={10.5281/zenodo.18467564},
  url={https://doi.org/10.5281/zenodo.18467564}
}
```

### Contributions and Authorship

Contributions are welcome! Please contact [Ben McEwen](benmcewen@outlook.com) to discuss potential contributions.

Contributors who make a substantial contribution will be recognised as authors in the citable DOI for subsequent releases. 

Substantial contributions include:
- Implementing a major feature or new functionality
- Significant refactoring or performance improvements
- Comprehensive documentation or tutorials
- Bug fixes that resolve critical issues

Minor contributions (small bug fixes, typos, formatting) will be acknowledged in the release notes.

## Acknowledgments

BaseAL uses embeddings pre-generated by [Bacpipe](https://github.com/bioacoustic-ai/bacpipe) developed by [Vincent Kather](https://github.com/vskode).

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The Active Learning Loop\n",
    "\n",
    "This notebook explains what active learning is and how the loop works.\n",
    "\n",
    "## What is Active Learning?\n",
    "\n",
    "**Problem:** Labeling data is expensive and time-consuming. You have 10,000 audio clips but can only afford to label 100.\n",
    "\n",
    "**Question:** Which 100 should you label to get the best model?\n",
    "\n",
    "**Active Learning Answer:** Don't pick randomly! Let the model tell you which samples would be most helpful.\n",
    "\n",
    "## The Core Loop\n",
    "\n",
    "```\n",
    "1. Start with:\n",
    "   - Small labeled set (e.g., 10 samples)\n",
    "   - Large unlabeled set (e.g., 990 samples)\n",
    "\n",
    "2. Train model on labeled set\n",
    "\n",
    "3. Use model to select \"informative\" samples from unlabeled set\n",
    "   (e.g., samples the model is uncertain about)\n",
    "\n",
    "4. Label those samples (human annotator)\n",
    "\n",
    "5. Add to labeled set\n",
    "\n",
    "6. Repeat steps 2-5 until satisfied\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "\n",
    "### Labeled vs Unlabeled Indices\n",
    "\n",
    "We maintain two lists:\n",
    "- `labeled_indices`: Indices of samples we've labeled (and can train on)\n",
    "- `unlabeled_indices`: Indices of samples we haven't labeled yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled: 5 samples\n",
      "Unlabeled: 95 samples\n",
      "\n",
      "Labeled indices: [0, 1, 2, 3, 4]\n",
      "Unlabeled indices (first 10): [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "# Simulating the state\n",
    "total_samples = 100\n",
    "\n",
    "# Start: 5 labeled, 95 unlabeled\n",
    "labeled_indices = [0, 1, 2, 3, 4]\n",
    "unlabeled_indices = list(range(5, 100))\n",
    "\n",
    "print(f\"Labeled: {len(labeled_indices)} samples\")\n",
    "print(f\"Unlabeled: {len(unlabeled_indices)} samples\")\n",
    "print(f\"\\nLabeled indices: {labeled_indices}\")\n",
    "print(f\"Unlabeled indices (first 10): {unlabeled_indices[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Strategies\n",
    "\n",
    "How do we select which unlabeled samples to label next?\n",
    "\n",
    "### 1. Random Sampling (Baseline)\n",
    "Just pick random samples. Simple but not optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected samples: [90, 42, 38, 32, 60]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_random(unlabeled_indices, n_samples=5):\n",
    "    \"\"\"Random sampling strategy\"\"\"\n",
    "    selected = np.random.choice(unlabeled_indices, size=n_samples, replace=False)\n",
    "    return selected.tolist()\n",
    "\n",
    "# Sample 5 random samples\n",
    "selected = sample_random(unlabeled_indices, n_samples=5)\n",
    "print(f\"Randomly selected samples: {selected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Uncertainty Sampling (Smarter)\n",
    "Pick samples the model is most uncertain about.\n",
    "\n",
    "**Intuition:** If the model predicts probabilities [0.51, 0.49], it's very uncertain! This sample would be informative.\n",
    "\n",
    "If the model predicts [0.99, 0.01], it's very confident. This sample is less informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty-based selected samples: [48, 60, 13, 78, 96]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def sample_uncertainty(model, embeddings, unlabeled_indices, n_samples=5):\n",
    "    \"\"\"Uncertainty sampling: select samples with highest prediction uncertainty\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get predictions for all unlabeled samples\n",
    "        X_unlabeled = embeddings[unlabeled_indices]\n",
    "        logits = model(X_unlabeled)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Uncertainty metric: entropy (higher = more uncertain)\n",
    "        # Or simpler: 1 - max_probability\n",
    "        max_probs, _ = torch.max(probs, dim=1)\n",
    "        uncertainty = 1 - max_probs\n",
    "        \n",
    "        # Select top-k most uncertain\n",
    "        top_k_indices = torch.topk(uncertainty, k=n_samples).indices\n",
    "        \n",
    "        # Convert back to original indices\n",
    "        selected = [unlabeled_indices[i] for i in top_k_indices.tolist()]\n",
    "    \n",
    "    return selected\n",
    "\n",
    "# Demo with fake data\n",
    "fake_model = torch.nn.Linear(10, 5)  # Fake model\n",
    "fake_embeddings = torch.randn(100, 10)\n",
    "\n",
    "selected = sample_uncertainty(fake_model, fake_embeddings, unlabeled_indices, n_samples=5)\n",
    "print(f\"Uncertainty-based selected samples: {selected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Samples to Labeled Set\n",
    "\n",
    "Once we've selected samples, we:\n",
    "1. Remove them from `unlabeled_indices`\n",
    "2. Add them to `labeled_indices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Labeled=5, Unlabeled=95\n",
      "After:  Labeled=10, Unlabeled=90\n",
      "\n",
      "Labeled indices: [0, 1, 2, 3, 4, 48, 60, 13, 78, 96]\n"
     ]
    }
   ],
   "source": [
    "def add_samples(labeled_indices, unlabeled_indices, selected_indices):\n",
    "    \"\"\"Move selected samples from unlabeled to labeled\"\"\"\n",
    "    for idx in selected_indices:\n",
    "        if idx in unlabeled_indices:\n",
    "            unlabeled_indices.remove(idx)\n",
    "            labeled_indices.append(idx)\n",
    "    return labeled_indices, unlabeled_indices\n",
    "\n",
    "# Add the selected samples\n",
    "print(f\"Before: Labeled={len(labeled_indices)}, Unlabeled={len(unlabeled_indices)}\")\n",
    "labeled_indices, unlabeled_indices = add_samples(labeled_indices, unlabeled_indices, selected)\n",
    "print(f\"After:  Labeled={len(labeled_indices)}, Unlabeled={len(unlabeled_indices)}\")\n",
    "print(f\"\\nLabeled indices: {labeled_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Active Learning Cycle\n",
    "\n",
    "Let's simulate one complete cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ACTIVE LEARNING CYCLE ===\n",
      "\n",
      "Step 1: Initial state\n",
      "  Labeled: 5\n",
      "  Unlabeled: 95\n",
      "\n",
      "Step 2: Training on labeled data...\n",
      "  Final loss: 0.8675\n",
      "\n",
      "Step 3: Selecting most informative samples...\n",
      "  Selected: [31, 94, 64, 74, 11]\n",
      "\n",
      "Step 4: Adding to labeled set...\n",
      "  Labeled: 10\n",
      "  Unlabeled: 90\n",
      "\n",
      "=== CYCLE COMPLETE ===\n",
      "We grew our labeled set from 5 to 10 samples!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Setup\n",
    "n_samples = 100\n",
    "n_features = 10\n",
    "n_classes = 3\n",
    "\n",
    "# Create fake dataset\n",
    "embeddings = torch.randn(n_samples, n_features)\n",
    "labels = torch.randint(0, n_classes, (n_samples,))\n",
    "\n",
    "# Initialize\n",
    "model = nn.Linear(n_features, n_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "labeled_indices = [0, 1, 2, 3, 4]  # Start with 5 labeled\n",
    "unlabeled_indices = list(range(5, n_samples))\n",
    "\n",
    "print(\"=== ACTIVE LEARNING CYCLE ===\")\n",
    "print(f\"\\nStep 1: Initial state\")\n",
    "print(f\"  Labeled: {len(labeled_indices)}\")\n",
    "print(f\"  Unlabeled: {len(unlabeled_indices)}\")\n",
    "\n",
    "# Train on labeled data\n",
    "print(f\"\\nStep 2: Training on labeled data...\")\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    X_train = embeddings[labeled_indices]\n",
    "    y_train = labels[labeled_indices]\n",
    "    logits = model(X_train)\n",
    "    loss = criterion(logits, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(f\"  Final loss: {loss.item():.4f}\")\n",
    "\n",
    "# Sample using uncertainty\n",
    "print(f\"\\nStep 3: Selecting most informative samples...\")\n",
    "selected = sample_uncertainty(model, embeddings, unlabeled_indices, n_samples=5)\n",
    "print(f\"  Selected: {selected}\")\n",
    "\n",
    "# Add to labeled set\n",
    "print(f\"\\nStep 4: Adding to labeled set...\")\n",
    "labeled_indices, unlabeled_indices = add_samples(labeled_indices, unlabeled_indices, selected)\n",
    "print(f\"  Labeled: {len(labeled_indices)}\")\n",
    "print(f\"  Unlabeled: {len(unlabeled_indices)}\")\n",
    "\n",
    "print(f\"\\n=== CYCLE COMPLETE ===\")\n",
    "print(f\"We grew our labeled set from 5 to {len(labeled_indices)} samples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Active Learning in 4 Steps:**\n",
    "1. **Train** on current labeled data\n",
    "2. **Sample** informative examples from unlabeled data\n",
    "3. **Label** those examples (human or oracle)\n",
    "4. **Add** to labeled set and repeat\n",
    "\n",
    "**Key Benefit:** You get better models with fewer labels!\n",
    "\n",
    "**In our implementation:**\n",
    "- `ActiveLearner` class manages this loop\n",
    "- API endpoints expose each step\n",
    "- Frontend visualizes the process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "active",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
